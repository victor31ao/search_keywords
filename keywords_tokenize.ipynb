{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188359 entries, 0 to 188358\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   searchkeyword  188359 non-null  object\n",
      " 1   count          188359 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./sample_data/searchkeyword.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_text(text:str) -> str:\n",
    "    # 去除 HTML 標籤\n",
    "    text = re.sub(r'<.*?>', ',', text)\n",
    "    # 去除非字母字符以及英文\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', ',', text)\n",
    "    text = re.sub(r\",+\", \",\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"searchkeyword\"] = df[\"searchkeyword\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>searchkeyword</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,白泥碳酸潔面泡</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,潔廁劑原味</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,劇</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,喇叭牌,正露丸,粒</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,歐萊雅</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>,蘭州歸脾丸</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,香港嶺南萬應筋健貼,科研榮譽出品,片包</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>,菲滋寶咀嚼片</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>,阿葵亞瞬效水光髪膜</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>,益生菌</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,蟲草</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>,口罩</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>,尿酸</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>,放大,舒特膚溫和潔膚露,毫升</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>,日本命力</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,蟲草大王</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>,卷</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>,抗菌除,翕洗衣液,公升</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>,修復強韌套裝</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>,油</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           searchkeyword  count\n",
       "0               ,白泥碳酸潔面泡      1\n",
       "1                 ,潔廁劑原味      1\n",
       "2                     ,劇      1\n",
       "3             ,喇叭牌,正露丸,粒      1\n",
       "4                   ,歐萊雅      1\n",
       "5                 ,蘭州歸脾丸      1\n",
       "6   ,香港嶺南萬應筋健貼,科研榮譽出品,片包      1\n",
       "7                ,菲滋寶咀嚼片      1\n",
       "8             ,阿葵亞瞬效水光髪膜      1\n",
       "9                   ,益生菌      4\n",
       "10                   ,蟲草      6\n",
       "11                   ,口罩      1\n",
       "12                   ,尿酸      2\n",
       "13       ,放大,舒特膚溫和潔膚露,毫升      1\n",
       "14                 ,日本命力      1\n",
       "15                 ,蟲草大王      1\n",
       "16                    ,卷      1\n",
       "17          ,抗菌除,翕洗衣液,公升      1\n",
       "18               ,修復強韌套裝      1\n",
       "19                    ,油      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OPEN_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/mtl/open_tok_pos_ner_srl_dep_sdp_con_electra_small_20201223_035557.zip',\n",
       " 'OPEN_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_BASE_ZH': 'https://file.hankcs.com/hanlp/mtl/open_tok_pos_ner_srl_dep_sdp_con_electra_base_20201223_201906.zip',\n",
       " 'CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/mtl/close_tok_pos_ner_srl_dep_sdp_con_electra_small_20210111_124159.zip',\n",
       " 'CLOSE_TOK_POS_NER_SRL_UDEP_SDP_CON_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/mtl/close_tok_pos_ner_srl_dep_sdp_con_electra_small_20220626_175100.zip',\n",
       " 'CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_BASE_ZH': 'https://file.hankcs.com/hanlp/mtl/close_tok_pos_ner_srl_dep_sdp_con_electra_base_20210111_124519.zip',\n",
       " 'CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ERNIE_GRAM_ZH': 'https://file.hankcs.com/hanlp/mtl/close_tok_pos_ner_srl_dep_sdp_con_ernie_gram_base_aug_20210904_145403.zip',\n",
       " 'UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_MMINILMV2L6': 'https://file.hankcs.com/hanlp/mtl/ud_ontonotes_tok_pos_lem_fea_ner_srl_dep_sdp_con_mMiniLMv2L6_no_space_20220731_161526.zip',\n",
       " 'UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_MMINILMV2L12': 'https://file.hankcs.com/hanlp/mtl/ud_ontonotes_tok_pos_lem_fea_ner_srl_dep_sdp_con_mMiniLMv2L12_no_space_20220807_133143.zip',\n",
       " 'UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_XLMR_BASE': 'https://file.hankcs.com/hanlp/mtl/ud_ontonotes_tok_pos_lem_fea_ner_srl_dep_sdp_con_xlm_base_20220608_003435.zip',\n",
       " 'NPCMJ_UD_KYOTO_TOK_POS_CON_BERT_BASE_CHAR_JA': 'https://file.hankcs.com/hanlp/mtl/npcmj_ud_kyoto_tok_pos_ner_dep_con_srl_bert_base_char_ja_20210914_133742.zip'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hanlp\n",
    "hanlp.pretrained.mtl.ALL\n",
    "# tok = hanlp.load(hanlp.pretrained.tok.MSR_TOK_ELECTRA_BASE_CRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://file.hankcs.com/hanlp/mtl/close_tok_pos_ner_srl_dep_sdp_con_electra_base_20210111_124519.zip to C:\\Users\\victo\\AppData\\Roaming\\hanlp\\mtl/close_tok_pos_ner_srl_dep_sdp_con_electra_base_20210111_124519.zip\n",
      "100% 467.9 MiB 412.3 KiB/s ETA:  0 s [=========================================]\n",
      "Decompressing C:\\Users\\victo\\AppData\\Roaming\\hanlp\\mtl/close_tok_pos_ner_srl_dep_sdp_con_electra_base_20210111_124519.zip to C:\\Users\\victo\\AppData\\Roaming\\hanlp\\mtl\n",
      "Downloading https://file.hankcs.com/corpus/char_table.json.zip to C:\\Users\\victo\\AppData\\Roaming\\hanlp\\thirdparty\\file.hankcs.com\\corpus/char_table.json.zip\n",
      "100%  19.4 KiB  19.4 KiB/s ETA:  0 s [=========================================]\n",
      "Decompressing C:\\Users\\victo\\AppData\\Roaming\\hanlp\\thirdparty\\file.hankcs.com\\corpus/char_table.json.zip to C:\\Users\\victo\\AppData\\Roaming\\hanlp\\thirdparty\\file.hankcs.com\\corpus\n",
      "                                   \r"
     ]
    }
   ],
   "source": [
    "HanLP = hanlp.load(hanlp.pretrained.mtl.CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_BASE_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: table; padding-bottom: 1rem;\"><pre style=\"display: table-cell; font-family: SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace; white-space: nowrap; line-height: 128%; padding: 0;\">,&nbsp;香港&nbsp;嶺南&nbsp;萬應&nbsp;筋健貼&nbsp;,&nbsp;科研&nbsp;榮譽&nbsp;出品&nbsp;,&nbsp;片包</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HanLP(',香港嶺南萬應筋健貼,科研榮譽出品,片包', tasks='tok').pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokenized\"] = df[\"searchkeyword\"].apply(lambda x: HanLP(x, tasks='tok'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>searchkeyword</th>\n",
       "      <th>count</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,白泥碳酸潔面泡</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tok/fine': [',', '白', '泥', '碳酸', '潔面', '泡']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,潔廁劑原味</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tok/fine': [',', '潔廁劑', '原味']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,劇</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tok/fine': [',', '劇']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,喇叭牌,正露丸,粒</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tok/fine': [',', '喇叭牌', ',', '正露丸', ',', '粒']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,歐萊雅</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tok/fine': [',', '歐萊雅']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188354</th>\n",
       "      <td>,芝孢子</td>\n",
       "      <td>8</td>\n",
       "      <td>{'tok/fine': [',', '芝', '孢子']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188355</th>\n",
       "      <td>,芝抱子</td>\n",
       "      <td>4</td>\n",
       "      <td>{'tok/fine': [',', '芝', '抱', '子']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188356</th>\n",
       "      <td>,芝苞子</td>\n",
       "      <td>3</td>\n",
       "      <td>{'tok/fine': [',', '芝苞', '子']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188357</th>\n",
       "      <td>,燒鵝</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tok/fine': [',', '燒', '鵝']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188358</th>\n",
       "      <td>,鼻</td>\n",
       "      <td>1</td>\n",
       "      <td>{'tok/fine': [',', '鼻']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188359 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       searchkeyword  count                                         tokenized\n",
       "0           ,白泥碳酸潔面泡      1    {'tok/fine': [',', '白', '泥', '碳酸', '潔面', '泡']}\n",
       "1             ,潔廁劑原味      1                  {'tok/fine': [',', '潔廁劑', '原味']}\n",
       "2                 ,劇      1                          {'tok/fine': [',', '劇']}\n",
       "3         ,喇叭牌,正露丸,粒      1  {'tok/fine': [',', '喇叭牌', ',', '正露丸', ',', '粒']}\n",
       "4               ,歐萊雅      1                        {'tok/fine': [',', '歐萊雅']}\n",
       "...              ...    ...                                               ...\n",
       "188354          ,芝孢子      8                    {'tok/fine': [',', '芝', '孢子']}\n",
       "188355          ,芝抱子      4                {'tok/fine': [',', '芝', '抱', '子']}\n",
       "188356          ,芝苞子      3                    {'tok/fine': [',', '芝苞', '子']}\n",
       "188357           ,燒鵝      1                     {'tok/fine': [',', '燒', '鵝']}\n",
       "188358            ,鼻      1                          {'tok/fine': [',', '鼻']}\n",
       "\n",
       "[188359 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./n_gram_processed/tokenized_by_hanlp.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
